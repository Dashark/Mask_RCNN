{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 基本信息\n",
    "在训练集或者验证集中标注了目标信息，可以计算\n",
    "\n",
    "1、目标的面积（多边形）\n",
    "\n",
    "2、目标的尺寸位置(x,y,width,height)\n",
    "\n",
    "3、宽高比\n",
    "\n",
    "4、目标的类别"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Mask RCNN\n",
    "# sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "from mrcnn import visualize\n",
    "############################################################\n",
    "#  Dataset\n",
    "############################################################\n",
    "\n",
    "class MyDataset(utils.Dataset):\n",
    "\n",
    "    def print_size(self, poly):\n",
    "        for p in poly:\n",
    "            a = np.array(p['all_points_y'])\n",
    "            height = a.max() - a.min()\n",
    "            a = np.array(p['all_points_x'])\n",
    "            width = a.max() - a.min()\n",
    "            self.areas.append(height * width)\n",
    "            #if height * width < 4096:\n",
    "            #    print(width, height)\n",
    "\n",
    "    def load_my(self, dataset_dir, subset, class_dict):\n",
    "        \"\"\"Load a subset of the My dataset.\n",
    "        dataset_dir: Root directory of the dataset.\n",
    "        subset: Subset to load: train or val\n",
    "        \"\"\"\n",
    "        self.areas = []\n",
    "        # Add classes. We have only one class to add.\n",
    "        for (k, v) in class_dict.items():\n",
    "            self.add_class(\"my\", v, k)\n",
    "\n",
    "        # Train or validation dataset?\n",
    "        assert subset in [\"train\", \"val\"]\n",
    "        dataset_dir = os.path.join(dataset_dir, subset)\n",
    "\n",
    "        # Load annotations\n",
    "        # VGG Image Annotator (up to version 1.6) saves each image in the form:\n",
    "        # { 'filename': '28503151_5b5b7ec140_b.jpg',\n",
    "        #   'regions': {\n",
    "        #       '0': {\n",
    "        #           'region_attributes': {},\n",
    "        #           'shape_attributes': {\n",
    "        #               'all_points_x': [...],\n",
    "        #               'all_points_y': [...],\n",
    "        #               'name': 'polygon'}},\n",
    "        #       ... more regions ...\n",
    "        #   },\n",
    "        #   'size': 100202\n",
    "        # }\n",
    "        # We mostly care about the x and y coordinates of each region\n",
    "        # Note: In VIA 2.0, regions was changed from a dict to a list.\n",
    "        annotations = json.load(open(os.path.join(dataset_dir, \"via_region_data.json\")))\n",
    "        annotations = list(annotations.values())  # don't need the dict keys\n",
    "\n",
    "        # The VIA tool saves images in the JSON even if they don't have any\n",
    "        # annotations. Skip unannotated images.\n",
    "        annotations = [a for a in annotations if a['regions']]\n",
    "\n",
    "        # Add images\n",
    "        for a in annotations:\n",
    "            # Get the x, y coordinaets of points of the polygons that make up\n",
    "            # the outline of each object instance. These are stores in the\n",
    "            # shape_attributes (see json format above)\n",
    "            # The if condition is needed to support VIA versions 1.x and 2.x.\n",
    "            # print(a['regions'])\n",
    "            # print(a['filename'])\n",
    "            if type(a['regions']) is dict:\n",
    "                polygons = [r['shape_attributes'] for r in a['regions'].values()]\n",
    "            else:\n",
    "                if a['regions']:\n",
    "                    class_ids = []\n",
    "                    polygons = []\n",
    "                    for r in a['regions']:\n",
    "                        polygons.append(r['shape_attributes'])\n",
    "                        class_type = r['region_attributes']['type']\n",
    "                        class_ids.append(class_dict[class_type])\n",
    "                        \n",
    "                    self.print_size(polygons)\n",
    "                    # print(class_ids)\n",
    "                        \n",
    "\n",
    "            # load_mask() needs the image size to convert polygons to masks.\n",
    "            # Unfortunately, VIA doesn't include it in JSON, so we must read\n",
    "            # the image. This is only managable since the dataset is tiny.\n",
    "                    image_path = os.path.join(dataset_dir, a['filename'])\n",
    "                    image = skimage.io.imread(image_path)\n",
    "                    height, width = image.shape[:2]\n",
    "\n",
    "                    self.add_image(\n",
    "                        \"my\",\n",
    "                        image_id=a['filename'],  # use file name as a unique image id\n",
    "                        path=image_path,\n",
    "                        width=width, height=height,\n",
    "                        polygons=polygons,\n",
    "                        class_ids=class_ids)\n",
    "        self.areas.sort()\n",
    "        print(np.unique(np.round(np.sqrt(self.areas))))\n",
    "\n",
    "class_dict = {}\n",
    "label_file = open(\"args.label\")\n",
    "label_lines = label_file.readlines()\n",
    "label_id = 1\n",
    "for label_line in label_lines:\n",
    "    label_line = label_line.replace('\\n', '')\n",
    "    class_dict[label_line] = label_id\n",
    "    label_id = label_id + 1\n",
    "# Validation dataset\n",
    "dataset_val = MyDataset()\n",
    "dataset_val.load_my(args.dataset, \"val\", class_dict)\n",
    "dataset_val.prepare()\n",
    "for image_id in dataset_val.image_ids:\n",
    "    image, image_meta, gt_class_id, gt_box, gt_mask = modellib.load_image_gt(dataset_val, config, image_id, use_mini_mask=False)\n"
   ]
  },
  {
   "source": [
    "# 目标的正方形尺寸\n",
    "\n",
    "上面已知标注的目标尺寸与宽高比，可以计算目标的正方形尺寸\n",
    "\n",
    "$$Size = \\lceil \\frac {width}{ \\sqrt {wh\\_ratio}} \\rceil$$\n",
    "\n",
    "尺寸$Size$向上取整。\n",
    "\n",
    "宽高比$wh\\_ratio$设定为小数点后一位，进位后舍弃后面的小数。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# 尺寸、宽高比分布\n",
    "\n",
    "横坐标为尺寸，纵坐标为宽高比，把所有标注目标绘制坐标图\n",
    "\n",
    "主要查看目标的分布情况，猜测分布会非常杂乱。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# 覆盖测试\n",
    "\n",
    "人工不可能把所有目标的尺寸和宽高比逐个设置。现实做法是设置几个代表性的尺寸，如32、64、128。代表性的宽高比，如0.5、1、2\n",
    "\n",
    "代表性数据不可能把所有目标都覆盖（IOU）\n",
    "\n",
    "根据上述坐标图的数据分布情况，设置代表性尺寸、宽高比，在每个目标上标识最大的交并比（IOU）。\n",
    "\n",
    "最大交并比（IOU）：理想值就是目标本身，但是以理想值为代表值，必然造成其它目标的交并比（IOU）下降。\n",
    "\n",
    "三维坐标图：尺寸、宽高比、IOU\n",
    "\n",
    "理想状态是IOU值足够高（0~1），足以用于目标的过滤。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# 代表性的尺寸、宽高比挑选（实验性）\n",
    "\n",
    "人工设置代表值达到IOU理想状态也不现实。。。\n",
    "\n",
    "怎么让计算机挑选代表值？"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}